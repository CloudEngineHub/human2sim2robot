seed: ${..seed}
network:
  separate_value_mlp: False

  mlp:
    units: [512, 256, 128]

ppo:
  multi_gpu: ${...multi_gpu}
  mixed_precision: False
  normalize_input: True
  normalize_value: True
  value_bootstrap: True
  num_actors: ${...task.env.numEnvs}
  reward_shaper:
    scale_value: 0.01
  normalize_advantage: True
  gamma: 0.99
  tau: 0.95
  learning_rate: 5e-4
  lr_schedule: adaptive
  schedule_type: standard
  kl_threshold: 0.016
  max_epochs: ${resolve_default:2_000_000,${...max_iterations}}
  save_best_after: 100
  save_frequency: 1000
  print_stats: True
  grad_norm: 1.0
  entropy_coef: 0.0
  truncate_grads: True
  e_clip: 0.2
  horizon_length: 8
  minibatch_size: 32768
  mini_epochs: 5
  critic_coef: 4
  seq_length: 4
  bounds_loss_coef: 0.0001

  # Must be None if empty (else gets error looking for keys in this dict)
  asymmetric_critic: ${if:${eval:"'empty' in '${...asymmetric_critic.name}'"},${eval:None},${...asymmetric_critic}}

player:
  deterministic: True
  games_num: 100_000
  print_stats: True
